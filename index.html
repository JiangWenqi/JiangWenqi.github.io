<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.1.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.1.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.1.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.1.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.1.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="大数据, 机器学习, 后端, 运维">
<meta name="keywords" content="Hdoop, Spark ML, Spring Boot, Docker">
<meta property="og:type" content="website">
<meta property="og:title" content="Vinci&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Vinci&#39;s Blog">
<meta property="og:description" content="大数据, 机器学习, 后端, 运维">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Vinci&#39;s Blog">
<meta name="twitter:description" content="大数据, 机器学习, 后端, 运维">





  
  
  <link rel="canonical" href="http://yoursite.com/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Vinci's Blog</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Vinci's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">学习笔记</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/Docker-Spark-历险记（二）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="姜文奇">
      <meta itemprop="description" content="大数据, 机器学习, 后端, 运维">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Vinci's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/04/Docker-Spark-历险记（二）/" class="post-title-link" itemprop="url">Docker Spark 历险记（二）</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-04-07 00:38:01" itemprop="dateCreated datePublished" datetime="2019-04-07T00:38:01+08:00">2019-04-07</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-04-10 00:57:28" itemprop="dateModified" datetime="2019-04-10T00:57:28+08:00">2019-04-10</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="运行你的第一个Spark应用"><a href="#运行你的第一个Spark应用" class="headerlink" title="运行你的第一个Spark应用"></a>运行你的第一个<code>Spark</code>应用</h2><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>通过这篇文章你能学习到什么，用简单的一句话描述就是：</p>
<p><strong>打包你的第一个<code>Scala</code>程序，并丢到之前创建好的<code>Spark</code>集群上运行。</strong></p>
<p>往复杂了说就是：</p>
<h2 id="Docker-部分"><a href="#Docker-部分" class="headerlink" title="Docker 部分"></a>Docker 部分</h2><ul>
<li><p>继续学习<code>Docker</code>常用操作，如：映射端口，挂载目录，传送变量等；</p>
</li>
<li><p>继续深入学习<code>Dockerfile</code>，熟悉<code>ARG</code>,<code>ENV</code>,<code>RUN</code>,<code>WORKDIR</code>,<code>CMD</code>等指令；</p>
</li>
</ul>
<h2 id="Scala-部分"><a href="#Scala-部分" class="headerlink" title="Scala 部分"></a>Scala 部分</h2><ul>
<li><code>Scala</code>基础语法，<code>Scala</code>编写第一个<code>Spark</code>应用程序；</li>
<li><code>SBT</code>通过配置清单，打包应用程序。</li>
</ul>
<h2 id="Spark-部分"><a href="#Spark-部分" class="headerlink" title="Spark 部分"></a>Spark 部分</h2><ul>
<li>提交编写好的<code>Scala</code>应用程序，<code>--class</code>主类。</li>
</ul>
<h1 id="配置Scala运行环境"><a href="#配置Scala运行环境" class="headerlink" title="配置Scala运行环境"></a>配置<code>Scala</code>运行环境</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><code>Spark</code>是用<code>Scala</code>编写的，所以这里我采用<code>Scala</code>语言进行编写程序。</p>
<p>基于上一篇所提到的<code>openjdk</code>镜像，继续编写<code>Dockerfile</code>：</p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Scala and sbt Dockerfile</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># https://github.com/spikerlabs/scala-sbt (based on https://github.com/hseeberger/scala-sbt)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Pull base image</span></span><br><span class="line"><span class="keyword">FROM</span>  openjdk:<span class="number">8</span>-alpine</span><br><span class="line"></span><br><span class="line"><span class="keyword">ARG</span> SCALA_VERSION</span><br><span class="line"><span class="keyword">ARG</span> SBT_VERSION</span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> SCALA_VERSION $&#123;SCALA_VERSION:-<span class="number">2.12</span>.<span class="number">8</span>&#125;</span><br><span class="line"><span class="keyword">ENV</span> SBT_VERSION $&#123;SBT_VERSION:-<span class="number">1.2</span>.<span class="number">7</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> \</span></span><br><span class="line"><span class="bash">  <span class="built_in">echo</span> <span class="string">"<span class="variable">$SCALA_VERSION</span> <span class="variable">$SBT_VERSION</span>"</span> &amp;&amp; \</span></span><br><span class="line"><span class="bash">  mkdir -p /usr/lib/jvm/java-1.8-openjdk/jre &amp;&amp; \</span></span><br><span class="line"><span class="bash">  touch /usr/lib/jvm/java-1.8-openjdk/jre/release &amp;&amp; \</span></span><br><span class="line"><span class="bash">  apk add --no-cache bash &amp;&amp; \</span></span><br><span class="line"><span class="bash">  apk add --no-cache curl &amp;&amp; \</span></span><br><span class="line"><span class="bash">  curl -fsL http://downloads.typesafe.com/scala/<span class="variable">$SCALA_VERSION</span>/scala-<span class="variable">$SCALA_VERSION</span>.tgz | tar xfz - -C /usr/<span class="built_in">local</span> &amp;&amp; \</span></span><br><span class="line"><span class="bash">  ln -s /usr/<span class="built_in">local</span>/scala-<span class="variable">$SCALA_VERSION</span>/bin/* /usr/<span class="built_in">local</span>/bin/ &amp;&amp; \</span></span><br><span class="line"><span class="bash">  scala -version &amp;&amp; \</span></span><br><span class="line"><span class="bash">  scalac -version</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> \</span></span><br><span class="line"><span class="bash">  curl -fsL https://github.com/sbt/sbt/releases/download/v<span class="variable">$SBT_VERSION</span>/sbt-<span class="variable">$SBT_VERSION</span>.tgz | tar xfz - -C /usr/<span class="built_in">local</span> &amp;&amp; \</span></span><br><span class="line"><span class="bash">  $(mv /usr/<span class="built_in">local</span>/sbt-launcher-packaging-<span class="variable">$SBT_VERSION</span> /usr/<span class="built_in">local</span>/sbt || <span class="literal">true</span>) \</span></span><br><span class="line"><span class="bash">  ln -s /usr/<span class="built_in">local</span>/sbt/bin/* /usr/<span class="built_in">local</span>/bin/ &amp;&amp; \</span></span><br><span class="line"><span class="bash">  sbt sbt-version || sbt sbtVersion || <span class="literal">true</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /project</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> <span class="string">"/usr/local/bin/sbt"</span></span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意<code>Dockerfile</code>开头的两个参数：<strong>SCALA_VERSION</strong>和<strong>SBT_VERSION</strong>是可以用户指定的。</p>
</blockquote>
<p>接着编译该<code>Dockerfile</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意最后的"."——当前目录</span></span><br><span class="line">docker build -t vinci/scala-sbt:latest \</span><br><span class="line">    --build-arg SCALA_VERSION=2.12.8 \</span><br><span class="line">    --build-arg SBT_VERSION=1.2.7 \</span><br><span class="line">    .</span><br></pre></td></tr></table></figure>
<blockquote>
<p>需要一段时间请耐心等待</p>
</blockquote>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>建立一个新的临时交互式容器进行测试：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --rm vinci/scala-sbt:latest /bin/bash</span><br></pre></td></tr></table></figure>
<p>依次输入：<code>scala -version</code>和<code>sbt sbtVersion</code></p>
<p>当容器里面的界面返回如下信息则说明安装成功。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bash-4.4<span class="comment"># scala -version</span></span><br><span class="line">Scala code runner version 2.12.8 -- Copyright 2002-2018, LAMP/EPFL and Lightbend, Inc.</span><br><span class="line">bash-4.4<span class="comment"># sbt sbtVersion</span></span><br><span class="line">[warn] No sbt.version <span class="built_in">set</span> <span class="keyword">in</span> project/build.properties, base directory: /<span class="built_in">local</span></span><br><span class="line">[info] Set current project to <span class="built_in">local</span> (<span class="keyword">in</span> build file:/<span class="built_in">local</span>/)</span><br><span class="line">[info] 1.2.7</span><br></pre></td></tr></table></figure>
<h1 id="挂载本地文件"><a href="#挂载本地文件" class="headerlink" title="挂载本地文件"></a>挂载本地文件</h1><p>为了让我们能够访问我们的本地文件，我们需要将一个卷从我们的工作目录安装到正在运行的容器上的某个位置。</p>
<p>我们只需在<code>run</code>指令里加上<code>-v</code>选项，如下所示：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/docker/projects/MyFirstScalaSpark</span><br><span class="line"><span class="built_in">cd</span> /root/docker/projects/MyFirstScalaSpark</span><br><span class="line">docker run -it --rm -v `<span class="built_in">pwd</span>`:/project vinci/scala-sbt:latest</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：</p>
<ol>
<li><code>pwd</code>是指当前目录（Linux 虚拟机：/root/docker/projects/MyFirstScalaSpark）；</li>
<li><code>/project</code>是映射到指容器里面的目录；</li>
<li>没有使用<code>/bin/bash</code>，可以直接登录到<code>SBT</code>控制台。</li>
</ol>
<p><strong>仔细看之前的Dockerfile配置，最后一行指定了默认执行的命令，倒数第二行指定了工作目录</strong></p>
</blockquote>
<p>登陆成功之后会返回如下信息：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost project]<span class="comment"># docker run -it --rm -v `pwd`:/project vinci/scala-sbt:latest</span></span><br><span class="line">[warn] No sbt.version <span class="built_in">set</span> <span class="keyword">in</span> project/build.properties, base directory: /<span class="built_in">local</span></span><br><span class="line">[info] Set current project to <span class="built_in">local</span> (<span class="keyword">in</span> build file:/<span class="built_in">local</span>/)</span><br><span class="line">[info] sbt server started at <span class="built_in">local</span>:///root/.sbt/1.0/server/05a53a1ec23bec1479e9/sock</span><br><span class="line">sbt:<span class="built_in">local</span>&gt;</span><br></pre></td></tr></table></figure>
<h1 id="第一个程序"><a href="#第一个程序" class="headerlink" title="第一个程序"></a>第一个程序</h1><h2 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h2><p>下面便可以开始编写你的第一个<code>Spark</code>程序了。</p>
<p>但是从上节的输出之中还可以看到<code>[warn]</code>，原因是没有设置<code>sbt</code>版本，也就是配置文件的问题。</p>
<p>那么我们在刚才创建的<code>project</code>目录下面新建——<strong>build.sbt</strong>，内容参考<a href="https://spark.apache.org/docs/latest/quick-start.html#self-contained-applications" target="_blank" rel="noopener">官方文档</a></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">name</span> <span class="string">:=</span> <span class="string">"MyFirstScalaSpark"</span></span><br><span class="line"><span class="string">version</span> <span class="string">:=</span> <span class="string">"0.1.0"</span></span><br><span class="line"><span class="string">scalaVersion</span> <span class="string">:=</span> <span class="string">"2.11.12"</span></span><br><span class="line"><span class="string">libraryDependencies</span> <span class="string">+=</span> <span class="string">"org.apache.spark"</span> <span class="string">%%</span> <span class="string">"spark-sql"</span> <span class="string">%</span> <span class="string">"2.4.0"</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>这为我们提供了一个最小的项目定义。 </p>
<p>注意：我们已经将Scala版本指定为2.11.12，因为Spark是针对Scala 2.11编译的，但容器上的Scala版本是2.12。 在SBT控制台中，运行reload命令以使用新的构建设置刷新SBT项目：</p>
</blockquote>
<img src="/2019/04/Docker-Spark-历险记（二）/SBT启动第一个程序.png" title="SBT启动第一个程序">
<h2 id="写代码"><a href="#写代码" class="headerlink" title="写代码"></a>写代码</h2><p>新建一个<code>SSH</code>连接到<code>CentOS</code>：</p>
<p>创建目录：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/docker/projects/MyFirstScalaSpark/src/main/scala/com/example</span><br><span class="line"><span class="built_in">cd</span> /root/docker/projects/MyFirstScalaSpark/src/main/scala/com/example</span><br><span class="line">vim MyFirstScalaSpark.scala</span><br></pre></td></tr></table></figure>
<p>内容如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">MyFirstScalaSpark</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">val</span> <span class="type">SPARK_HOME</span> = sys.env(<span class="string">"SPARK_HOME"</span>)</span><br><span class="line">    <span class="keyword">val</span> logFile = <span class="string">s"<span class="subst">$&#123;SPARK_HOME&#125;</span>/README.md"</span></span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder</span><br><span class="line">      .appName(<span class="string">"MyFirstScalaSpark"</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    <span class="keyword">val</span> logData = spark.read.textFile(logFile).cache()</span><br><span class="line">    <span class="keyword">val</span> numAs = logData.filter(line =&gt; line.contains(<span class="string">"a"</span>)).count()</span><br><span class="line">    <span class="keyword">val</span> numBs = logData.filter(line =&gt; line.contains(<span class="string">"b"</span>)).count()</span><br><span class="line">    println(<span class="string">s"Lines with a: <span class="subst">$numAs</span>, Lines with b: <span class="subst">$numBs</span>"</span>)</span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="打包"><a href="#打包" class="headerlink" title="打包"></a>打包</h2><p>进入到<code>sbt</code>容器，输入</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">package</span><br></pre></td></tr></table></figure>
<p>等待很长一段时间，便会出现如下界面，说明打包成功：</p>
<img src="/2019/04/Docker-Spark-历险记（二）/打包.png" title="打包">
<h2 id="提交任务"><a href="#提交任务" class="headerlink" title="提交任务"></a>提交任务</h2><p>打包好的 <code>jar</code>包在：<code>/root/docker/projects/MyFirstScalaSpark/target/scala-2.11</code>目录下</p>
<h3 id="启动Spark集群（详见第一章）："><a href="#启动Spark集群（详见第一章）：" class="headerlink" title="启动Spark集群（详见第一章）："></a>启动<code>Spark</code>集群（详见第一章）：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /root/docker/spark</span><br><span class="line">docker-compose up --scale spark-worker=2</span><br></pre></td></tr></table></figure>
<h3 id="启动Spark客户端容器"><a href="#启动Spark客户端容器" class="headerlink" title="启动Spark客户端容器"></a>启动<code>Spark</code>客户端容器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /root/docker/projects/MyFirstScalaSpark</span><br><span class="line">docker run --rm -it -e SPARK_MASTER=<span class="string">"spark://spark-master:7077"</span> \</span><br><span class="line">  -v `<span class="built_in">pwd</span>`:/project --network spark_spark-network \</span><br><span class="line">  vinci/spark:latest /bin/bash</span><br></pre></td></tr></table></figure>
<h3 id="提交任务-1"><a href="#提交任务-1" class="headerlink" title="提交任务"></a>提交任务</h3><p>进入到<code>Spark</code>客户端容器，输入以下语句：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --master <span class="variable">$SPARK_MASTER</span> \</span><br><span class="line">	--class com.example.MyFirstScalaSpark \</span><br><span class="line">    /project/target/scala-2.11/myfirstscalaspark_2.11-0.1.0.jar</span><br></pre></td></tr></table></figure>
<p>结果输出：</p>
<blockquote>
<p>Lines with a: 62, Lines with b: 31</p>
</blockquote>
<p>执行成功。</p>
<p>本章到此结束。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/Docker-Spark-历险记（一）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="姜文奇">
      <meta itemprop="description" content="大数据, 机器学习, 后端, 运维">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Vinci's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/04/Docker-Spark-历险记（一）/" class="post-title-link" itemprop="url">Docker Spark 历险记（一）</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-04-05 23:16:29" itemprop="dateCreated datePublished" datetime="2019-04-05T23:16:29+08:00">2019-04-05</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-04-10 00:56:50" itemprop="dateModified" datetime="2019-04-10T00:56:50+08:00">2019-04-10</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Docker/" itemprop="url" rel="index"><span itemprop="name">Docker</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="一键在Docker上部署属于你自己的Spark计算平台"><a href="#一键在Docker上部署属于你自己的Spark计算平台" class="headerlink" title="一键在Docker上部署属于你自己的Spark计算平台"></a>一键在Docker上部署属于你自己的Spark计算平台</h2><img src="/2019/04/Docker-Spark-历险记（一）/文章Logo.jpg">
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>阅读这篇文章之后，你可以学到什么：<br>简单来说就是，可以通过一个命令启动一个 <code>Spark</code> 集群，然后执行你的计算任务。<br>往复杂了说：</p>
<h2 id="Docker-相关知识点："><a href="#Docker-相关知识点：" class="headerlink" title="Docker 相关知识点："></a><code>Docker</code> 相关知识点：</h2><ul>
<li><code>Docker</code> 安装及常见指令；</li>
<li><code>Dockerfile</code> 构建镜像；</li>
<li><code>Docker Compose</code> 一键部署；</li>
<li><code>Docker network</code> 环境配置。</li>
</ul>
<h2 id="Spark-相关知识点："><a href="#Spark-相关知识点：" class="headerlink" title="Spark 相关知识点："></a><code>Spark</code> 相关知识点：</h2><ul>
<li><code>Spark</code> 集群安装及配置；</li>
<li><code>Spark master</code> 及 <code>worker</code> 启动与协作；</li>
<li><code>Spark Job</code> 提交及测试 等等。</li>
</ul>
<hr>
<h1 id="准备虚拟机"><a href="#准备虚拟机" class="headerlink" title="准备虚拟机"></a>准备虚拟机</h1><blockquote>
<p>CentOS-7-x86_64-Minimal-1810.iso</p>
<p>桥接模式</p>
</blockquote>
<p>进入虚拟机之后，查询 <code>ip</code> 地址，需要用到：<strong>ipconfig</strong> 指令，所以输入如下指令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install net-tools -y</span><br></pre></td></tr></table></figure>
<p>然后便可以使用<code>ifconfig</code>指令查询<code>ip</code>地址：<code>ssh root@192.168.199.240</code></p>
<hr>
<h1 id="安装-Docker"><a href="#安装-Docker" class="headerlink" title="安装 Docker"></a>安装 Docker</h1><p>参照：<a href="https://docs.docker.com/install/linux/docker-ce/centos/" target="_blank" rel="noopener">官方文档</a></p>
<h2 id="卸载旧版本（可选）"><a href="#卸载旧版本（可选）" class="headerlink" title="卸载旧版本（可选）"></a>卸载旧版本（可选）</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo yum remove docker \</span><br><span class="line">                  docker-client \</span><br><span class="line">                  docker-client-latest \</span><br><span class="line">                  docker-common \</span><br><span class="line">                  docker-latest \</span><br><span class="line">                  docker-latest-logrotate \</span><br><span class="line">                  docker-logrotate \</span><br><span class="line">                  docker-engine</span><br></pre></td></tr></table></figure>
<h2 id="安装-Docker-CE"><a href="#安装-Docker-CE" class="headerlink" title="安装 Docker CE"></a>安装 Docker CE</h2><blockquote>
<p>官方介绍有三种方式进行安装，但是我们这里选用最简单的方式，也是官方最为推荐的方式进行安装。</p>
</blockquote>
<h3 id="配置-repository"><a href="#配置-repository" class="headerlink" title="配置 repository"></a>配置 repository</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 所需依赖包</span></span><br><span class="line">sudo yum install -y yum-utils \</span><br><span class="line">  device-mapper-persistent-data \</span><br><span class="line">  lvm2</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 官方推荐稳定版本</span></span><br><span class="line">sudo yum-config-manager \</span><br><span class="line">  --add-repo \</span><br><span class="line">  https://download.docker.com/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure>
<h3 id="安装-Docker-CE-1"><a href="#安装-Docker-CE-1" class="headerlink" title="安装 Docker CE"></a>安装 Docker CE</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure>
<h3 id="启动-Docker-CE"><a href="#启动-Docker-CE" class="headerlink" title="启动 Docker CE"></a>启动 Docker CE</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start docker</span><br></pre></td></tr></table></figure>
<h3 id="检测-Docker-CE-安装是否成功"><a href="#检测-Docker-CE-安装是否成功" class="headerlink" title="检测 Docker CE 安装是否成功"></a>检测 Docker CE 安装是否成功</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run hello-world</span><br></pre></td></tr></table></figure>
<img src="/2019/04/Docker-Spark-历险记（一）/Docker安装成功界面.png">
<hr>
<h1 id="Docker-切换到国内镜像（可选）"><a href="#Docker-切换到国内镜像（可选）" class="headerlink" title="Docker 切换到国内镜像（可选）"></a>Docker 切换到国内镜像（可选）</h1><p>国内镜像有很多，如：阿里，中科院大学 等等，这里我选用的<code>docker-cn</code></p>
<p>具体操作如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/docker/daemon.json</span><br></pre></td></tr></table></figure>
<p>加入：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"registry-mirrors"</span>: [<span class="string">"https://registry.docker-cn.com"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后重启<code>Docker</code>就好了</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="搭建Spark服务"><a href="#搭建Spark服务" class="headerlink" title="搭建Spark服务"></a>搭建<code>Spark</code>服务</h1><p>参见国外文章：<a href="https://towardsdatascience.com/a-journey-into-big-data-with-apache-spark-part-1-5dfcc2bccdd2" target="_blank" rel="noopener">https://towardsdatascience.com/a-journey-into-big-data-with-apache-spark-part-1-5dfcc2bccdd2</a></p>
<p>这一节的大体步骤是：</p>
<ol>
<li>拉去一个基础镜像；</li>
<li>在基础镜像的基础上，添加必要的工具类和<code>Spark</code>安装包；</li>
<li>然后配置脚本，让<code>Spark</code>运行起来。</li>
</ol>
<p>注：其中最主要有两个文件：</p>
<ul>
<li>一个是<code>Dockerfile</code>——配置镜像的所有操作；</li>
<li>一个是<code>docker-compose.yml</code>——一键启动集群。</li>
</ul>
<h2 id="获取Open-JDK-基础镜像"><a href="#获取Open-JDK-基础镜像" class="headerlink" title="获取Open JDK(基础镜像)"></a>获取<code>Open JDK</code>(基础镜像)</h2><p>这里是通过 <code>Dockerfile</code>来自己创建镜像。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /root</span><br><span class="line">mkdir docker</span><br><span class="line">vim Dockerfile</span><br></pre></td></tr></table></figure>
<p>创建一个空白的<code>Dockerfile</code>之后，填入以下配置：</p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> openjdk:<span class="number">8</span>-alpine</span><br></pre></td></tr></table></figure>
<p>然后便可以进行编译了，最好是打上自己的标签（将 <code>$MYNAME</code>替换成你的名字），如下所示：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker build -t <span class="variable">$MYNAME</span>/spark:latest .</span><br><span class="line"></span><br><span class="line">docker build -t vinci/spark:latest .</span><br></pre></td></tr></table></figure>
<img src="/2019/04/Docker-Spark-历险记（一）/OpenJDK编译结果.png">
<h2 id="添加工具类"><a href="#添加工具类" class="headerlink" title="添加工具类"></a>添加工具类</h2><p>上面所建的 <code>openjdk</code>镜像里面是没有任何工具类的，但是我们下载<code>Spark</code>时需要用到<code>wget</code>，以及<code>tar</code>解压等工具，所以继续在<code>Dockerfile</code>里面添加配置：（新增一行，<strong>注意添加 –update</strong>）</p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> apk --update add wget tar bash</span></span><br></pre></td></tr></table></figure>
<p>然后便可以重新编译镜像了(语句跟之前一样)：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t vinci/spark:latest .</span><br></pre></td></tr></table></figure>
<img src="/2019/04/Docker-Spark-历险记（一）/镜像添加工具类.png">
<h2 id="下载Spark"><a href="#下载Spark" class="headerlink" title="下载Spark"></a>下载<code>Spark</code></h2><p>我们用最新的<code>Spark 2.4.0</code>基于<code>Scala 2.11</code> 和<code>Hadoop 2.7</code>，继续在<code>Dockerfile</code>里新增命令：</p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 原作者的链接 404了，我去apache官网上找了个一模一样的</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> wget https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压并删除多余压缩包</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> tar -xzf spark-2.4.0-bin-hadoop2.7.tgz &amp;&amp; \</span></span><br><span class="line"><span class="bash">    mv spark-2.4.0-bin-hadoop2.7 /spark &amp;&amp; \</span></span><br><span class="line"><span class="bash">    rm spark-2.4.0-bin-hadoop2.7.tgz</span></span><br></pre></td></tr></table></figure>
<p>再次重新编译：<code>docker build -t vinci/spark:latest .</code> </p>
<blockquote>
<p>下载耗时较长，请耐心等待</p>
</blockquote>
<h2 id="测试一下"><a href="#测试一下" class="headerlink" title="测试一下"></a>测试一下</h2><p><code>Spark</code>下载完成之后，便可以<code>run</code>一个容器进行测试：</p>
<p>这里需要注意的是：<code>Spark Master</code> 和 <code>Worker</code> 需要进行通信，所以需要指明端口映射：<code>-p 7077:7077 -p 8080:8080</code>，其中<code>8080</code>端口是<code>WEB-UI</code>的端口：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -it --name spark-master --hostname spark-master \</span><br><span class="line">    -p 7077:7077 -p 8080:8080 <span class="variable">$MYNAME</span>/spark:latest /bin/sh</span><br><span class="line"><span class="comment"># 这是一个运行完之后就会删除的容器</span></span><br><span class="line">docker run --rm -it --name spark-master --hostname spark-master \</span><br><span class="line">    -p 7077:7077 -p 8080:8080 vinci/spark:latest /bin/sh</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这样就进入到了容器里面，然后我们新建一个窗口，用<code>SSH</code>连接到虚拟里面，输入<code>docker container ls</code>，可以查看到当前正在运行的<strong>容器的状态</strong>，如下图所示：</p>
</blockquote>
<img src="/2019/04/Docker-Spark-历险记（一）/容器状态查看.png" title="容器状态查看">
<p>在<code>Spark-master</code>容器中（就是上面进入的容器），输入以下指令启动<code>Spark</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/spark/bin/spark-class org.apache.spark.deploy.master.Master --ip `hostname` --port 7077 --webui-port 8080</span><br></pre></td></tr></table></figure>
<img src="/2019/04/Docker-Spark-历险记（一）/Spark启动成功.png">
<p>然后可以去浏览器确认<code>Spark</code>是否成功启动：</p>
<img src="/2019/04/Docker-Spark-历险记（一）/Spark启动成功1.png">
<hr>
<h1 id="搭建Spark集群"><a href="#搭建Spark集群" class="headerlink" title="搭建Spark集群"></a>搭建<code>Spark</code>集群</h1><p>以上测试成功之后，退出容器，容器便自动删除了（因为启动容器的时候加了<code>rm</code>选项）。</p>
<h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>找到<code>/etc/sysctl.conf</code></p>
<p>新增一条：<code>net.ipv4.ip_forward=1</code></p>
<p>重启网络：<code>systemctl restart network</code></p>
<p>验证配置：<code>sysctl net.ipv4.ip_forward</code></p>
<h2 id="为本地群集创建一个网络"><a href="#为本地群集创建一个网络" class="headerlink" title="为本地群集创建一个网络"></a>为本地群集创建一个网络</h2><p> 创建网络非常简单，可以通过运行以下命令来完成：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network create spark_network</span><br></pre></td></tr></table></figure>
<h2 id="启动Spark-Master"><a href="#启动Spark-Master" class="headerlink" title="启动Spark-Master"></a>启动<code>Spark-Master</code></h2><p>删除之前建立的<code>Spark-Master</code>容器（默认已经删除了），然后启动指定网络的<code>Spark-Master</code>，只需要加上<code>--network</code>选项，如下所示：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -it --name spark-master --hostname spark-master \</span><br><span class="line">    -p 7077:7077 -p 8080:8080 --network spark_network \</span><br><span class="line">    <span class="variable">$MYNAME</span>/spark:latest /bin/sh</span><br><span class="line">    </span><br><span class="line">docker run --rm -it --name spark-master --hostname spark-master \</span><br><span class="line">    -p 7077:7077 -p 8080:8080 --network spark_network \</span><br><span class="line">    vinci/spark:latest /bin/sh</span><br></pre></td></tr></table></figure>
<p>进入到容器内部，输入以下指令启动：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/spark/bin/spark-class org.apache.spark.deploy.master.Master --ip `hostname` --port 7077 --webui-port 8080</span><br></pre></td></tr></table></figure>
<h2 id="启动Spark-Worker"><a href="#启动Spark-Worker" class="headerlink" title="启动Spark-Worker"></a>启动<code>Spark-Worker</code></h2><p>重新建立一个<code>SSH</code>对话，连接到虚拟机，输入以下指令启动<code>Spark-Worker</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -it --name spark-worker1 --hostname spark-worker1 \</span><br><span class="line">    --network spark_network \</span><br><span class="line">    <span class="variable">$MYNAME</span>/spark:latest /bin/sh</span><br><span class="line">    </span><br><span class="line">docker run --rm -it --name spark-worker1 --hostname spark-worker1 \</span><br><span class="line">    --network spark_network \</span><br><span class="line">    vinci/spark:latest /bin/sh</span><br></pre></td></tr></table></figure>
<p>进入到<code>worker</code>容器中之后，启动<code>Spark-Worker</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/spark/bin/spark-class org.apache.spark.deploy.worker.Worker \</span><br><span class="line">    --webui-port 8080 spark://spark-master:7077</span><br></pre></td></tr></table></figure>
<img src="/2019/04/Docker-Spark-历险记（一）/Worker启动成功.png">
<blockquote>
<p>注：此时回看<code>Spark-Master</code>容器，会发现多了一行日志：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INFO  Master:54 - Registering worker 172.18.0.3:36486 with 2 cores, 1024.0 MB RAM</span><br></pre></td></tr></table></figure>
<p><strong>至此，Spark 集群已经安装成功了</strong></p>
<h1 id="Spark集群实践"><a href="#Spark集群实践" class="headerlink" title="Spark集群实践"></a><code>Spark</code>集群实践</h1><p>一般是<code>一主两从</code>集群架构，所以我们还可以新建一个<code>Spark-Work2</code>容器，指令跟之前相似：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -it --name spark-worker2 --hostname spark-worker2 \</span><br><span class="line">    --network spark_network \</span><br><span class="line">    vinci/spark:latest /bin/sh</span><br></pre></td></tr></table></figure>
<p>进入<code>spark-worker2</code>容器之后，继续启动<code>Spark-Worker</code>服务：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/spark/bin/spark-class org.apache.spark.deploy.worker.Worker \</span><br><span class="line">    --webui-port 8080 spark://spark-master:7077</span><br></pre></td></tr></table></figure>
<p>然后宿主机，浏览器输入：<code>虚拟机IP:8080</code>，验证<code>Spark</code>服务：</p>
<img src="/2019/04/Docker-Spark-历险记（一）/Spark集群成功启动.png">
<h2 id="运行计算"><a href="#运行计算" class="headerlink" title="运行计算"></a>运行计算</h2><p>再次启动一个容器进入到<code>spark-network</code>中：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -it --network spark_network \</span><br><span class="line">    <span class="variable">$MYNAME</span>/spark:latest /bin/sh</span><br><span class="line">    </span><br><span class="line">docker run --rm -it --network spark_network \</span><br><span class="line">    vinci/spark:latest /bin/sh</span><br></pre></td></tr></table></figure>
<p>运行官方提供的样例：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/spark/bin/spark-submit --master spark://spark-master:7077 --class \</span><br><span class="line">    org.apache.spark.examples.SparkPi \</span><br><span class="line">    /spark/examples/jars/spark-examples_2.11-2.4.0.jar 1000</span><br></pre></td></tr></table></figure>
<p>运行之后会看到哗啦啦的日志输出，我们也可以通过<code>Web-UI</code>来进行监控。</p>
<img src="/2019/04/Docker-Spark-历险记（一）/Spark运行pi计算结果.png">
<hr>
<h1 id="Docker-Compose"><a href="#Docker-Compose" class="headerlink" title="Docker Compose"></a>Docker Compose</h1><p>通过<code>Docker Compose</code>可以极大简化我们的安装部署流程。</p>
<p><strong>这一节将对之前的知识点进行汇总，所以嫌麻烦的可以不看前面，直接看这里。</strong></p>
<h2 id="配置-Docker-Compose"><a href="#配置-Docker-Compose" class="headerlink" title="配置 Docker Compose"></a>配置 Docker Compose</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo curl -L <span class="string">"https://github.com/docker/compose/releases/download/1.23.1/docker-compose-<span class="variable">$(uname -s)</span>-<span class="variable">$(uname -m)</span>"</span> -o /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line"></span><br><span class="line">sudo chmod +x /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line"></span><br><span class="line">docker-compose --version</span><br></pre></td></tr></table></figure>
<h2 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h2><p>为容器添加<code>Spark</code>的环境变量，这样就不需要输入前面一大串绝对路径了。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /root/docker/spark</span><br><span class="line">vim bashrc</span><br></pre></td></tr></table></figure>
<p>添加环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SPARK_HOME=/spark</span><br><span class="line">PATH=$PATH:$SPARK_HOME/bin</span><br></pre></td></tr></table></figure>
<h2 id="启动脚本"><a href="#启动脚本" class="headerlink" title="启动脚本"></a>启动脚本</h2><p>启动脚本也就是之前我们进入容器输入的启动<code>spark-master</code>或者<code>spark-worker</code>的命令。</p>
<p>注意脚本的第一行必须是：<code>#!/bin/bash</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/docker/spark/scripts</span><br><span class="line">cd /root/docker/spark/scripts</span><br><span class="line">vim start-master.sh</span><br><span class="line">vim start-worker.sh</span><br><span class="line">vim start-all.sh</span><br></pre></td></tr></table></figure>
<h3 id="Start-master"><a href="#Start-master" class="headerlink" title="Start-master"></a>Start-master</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">source /root/.bashrc</span><br><span class="line"></span><br><span class="line">export SPARK_MASTER_HOST=`hostname`</span><br><span class="line"></span><br><span class="line">mkdir -p $SPARK_MASTER_LOG</span><br><span class="line"></span><br><span class="line">export SPARK_HOME=/spark</span><br><span class="line"></span><br><span class="line">ln -sf /dev/stdout $SPARK_MASTER_LOG/spark-master.out</span><br><span class="line"></span><br><span class="line">spark-class org.apache.spark.deploy.master.Master \</span><br><span class="line">	--ip $SPARK_MASTER_HOST \</span><br><span class="line">	--port $SPARK_MASTER_PORT \</span><br><span class="line">	--webui-port $SPARK_MASTER_WEBUI_PORT &gt;&gt; $SPARK_MASTER_LOG/spark-master.out</span><br></pre></td></tr></table></figure>
<h3 id="Start-worker"><a href="#Start-worker" class="headerlink" title="Start-worker"></a>Start-worker</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">source /root/.bashrc</span><br><span class="line"></span><br><span class="line">mkdir -p $SPARK_WORKER_LOG</span><br><span class="line"></span><br><span class="line">export SPARK_HOME=/spark</span><br><span class="line"></span><br><span class="line">ln -sf /dev/stdout $SPARK_WORKER_LOG/spark-worker.out</span><br><span class="line"></span><br><span class="line">spark-class org.apache.spark.deploy.worker.Worker \</span><br><span class="line">	--webui-port $SPARK_WORKER_WEBUI_PORT \</span><br><span class="line"><span class="meta">	$</span><span class="bash">SPARK_MASTER &gt;&gt; <span class="variable">$SPARK_WORKER_LOG</span>/spark-worker.out</span></span><br></pre></td></tr></table></figure>
<h3 id="Start-shell"><a href="#Start-shell" class="headerlink" title="Start-shell"></a>Start-shell</h3><p>这个<code>start-shell.sh</code>脚本的作用是，在运行容器时，默认就进入<code>spark-shell</code>：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">source /root/.bashrc</span><br><span class="line"></span><br><span class="line">export SPARK_MASTER_HOST=`hostname`</span><br><span class="line"></span><br><span class="line">mkdir -p $SPARK_MASTER_LOG</span><br><span class="line"></span><br><span class="line">export SPARK_HOME=/spark</span><br><span class="line"></span><br><span class="line">ln -sf /dev/stdout $SPARK_MASTER_LOG/spark-master.out</span><br><span class="line"></span><br><span class="line">spark-class org.apache.spark.deploy.master.Master \ </span><br><span class="line">	--ip $SPARK_MASTER_HOST \</span><br><span class="line">    --port 	$SPARK_MASTER_PORT \ </span><br><span class="line">    --webui-port $SPARK_MASTER_WEBUI_PORT &gt;&gt; $SPARK_MASTER_LOG/spark-master.out</span><br></pre></td></tr></table></figure>
<blockquote>
<p>脚本创建完成之后赋予可执行权限：<code>chmod +x start-master.sh start-worker.sh start-shell.sh</code></p>
</blockquote>
<h2 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h2><p>有了这些脚本之后便可以构建自己所需要的<code>Spark</code>镜像了。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /root/docker/spark</span><br><span class="line">vim Dockerfile</span><br></pre></td></tr></table></figure>
<p>内容如下：</p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> openjdk:<span class="number">8</span>-alpine</span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> SPARK_MASTER_PORT <span class="number">7077</span></span><br><span class="line"><span class="keyword">ENV</span> SPARK_MASTER_WEBUI_PORT <span class="number">8080</span></span><br><span class="line"><span class="keyword">ENV</span> SPARK_MASTER_LOG /spark/logs</span><br><span class="line"><span class="keyword">ENV</span> SPARK_WORKER_LOG /spark/logs</span><br><span class="line"><span class="keyword">ENV</span> SPARK_VERSION <span class="number">2.4</span>.<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 工具类</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apk --update --no-cache add \</span></span><br><span class="line"><span class="bash">        wget tar bash</span></span><br><span class="line"><span class="comment"># Spark 压缩包下载</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> wget https://archive.apache.org/dist/spark/spark-<span class="variable">$&#123;SPARK_VERSION&#125;</span>/spark-<span class="variable">$&#123;SPARK_VERSION&#125;</span>-bin-hadoop2.7.tgz</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压并删除多余压缩包</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> tar -xzf spark-<span class="variable">$&#123;SPARK_VERSION&#125;</span>-bin-hadoop2.7.tgz &amp;&amp; \</span></span><br><span class="line"><span class="bash">    mv spark-<span class="variable">$&#123;SPARK_VERSION&#125;</span>-bin-hadoop2.7 /spark &amp;&amp; \</span></span><br><span class="line"><span class="bash">    rm spark-<span class="variable">$&#123;SPARK_VERSION&#125;</span>-bin-hadoop2.7.tgz</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 复制环境变量</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> bashrc /root/.bashrc</span></span><br><span class="line"><span class="comment"># 复制启动脚本(包括启动Master和Worker)到容器根目录</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> scripts/* /</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 暴露端口</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">8080</span> <span class="number">7077</span> <span class="number">6066</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 默认启动 Spark-shell 暂不开启</span></span><br><span class="line"><span class="comment"># ENTRYPOINT ["/start-shell.sh"]</span></span><br></pre></td></tr></table></figure>
<p>然后编译镜像</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t vinci/spark:latest .</span><br></pre></td></tr></table></figure>
<p>编译完成之后进入容器检查一下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -it --network spark_network \</span><br><span class="line">    vinci/spark:latest /bin/sh</span><br></pre></td></tr></table></figure>
<img src="/2019/04/Docker-Spark-历险记（一）/启动脚本添加到容器里面.png">
<h2 id="编写docker-compose-yml"><a href="#编写docker-compose-yml" class="headerlink" title="编写docker-compose.yml"></a>编写<code>docker-compose.yml</code></h2><p>创建一个新文件：<code>docker-compose.yml</code>，输入以下配置：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">"3.3"</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"><span class="attr">  spark-master:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">vinci/spark:latest</span></span><br><span class="line"><span class="attr">    container_name:</span> <span class="string">spark-master</span></span><br><span class="line"><span class="attr">    hostname:</span> <span class="string">spark-master</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8080:8080"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"7077:7077"</span></span><br><span class="line"><span class="attr">    networks:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">spark-network</span></span><br><span class="line"><span class="attr">    environment:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"SPARK_LOCAL_IP=spark-master"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"SPARK_MASTER_PORT=7077"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"SPARK_MASTER_WEBUI_PORT=8080"</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">"/start-master.sh"</span></span><br><span class="line"><span class="attr">  spark-worker:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">vinci/spark:latest</span></span><br><span class="line"><span class="attr">    depends_on:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">spark-master</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">    networks:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">spark-network</span></span><br><span class="line"><span class="attr">    environment:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"SPARK_MASTER=spark://spark-master:7077"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"SPARK_WORKER_WEBUI_PORT=8080"</span></span><br><span class="line"><span class="attr">    entrypoint:</span> <span class="string">"/start-worker.sh"</span></span><br><span class="line"><span class="attr">    volumes:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"./:/local"</span></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line"><span class="attr">  spark-network:</span></span><br><span class="line"><span class="attr">    driver:</span> <span class="string">bridge</span></span><br><span class="line"><span class="attr">    ipam:</span></span><br><span class="line"><span class="attr">      driver:</span> <span class="string">default</span></span><br></pre></td></tr></table></figure>
<p>接下来要做的事情就很简单了，直接运行以下命令就行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose up --scale spark-worker=3</span><br></pre></td></tr></table></figure>
<p>其中<code>--scale</code>作用是：Sets the number of containers to run for a service.</p>
 
<p>运行成功之后可以新建一个<code>SSH</code>连接到虚拟机<code>CentOS</code>上，输入<code>docker container ls</code>查看当前正在运行的容器：</p>
<img src="/2019/04/Docker-Spark-历险记（一）/正在运行的容器.png">
<h2 id="测试一下-1"><a href="#测试一下-1" class="headerlink" title="测试一下"></a>测试一下</h2><p>需要注意的是，这里通过<code>docker-compose</code>启动<code>spark</code>集群的方式，<code>net-work</code>的名字叫做：<strong>spark_spark-network</strong></p>
<img src="/2019/04/Docker-Spark-历险记（一）/docker-network.png">
<p>启动测试容器：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -it --network spark_spark-network vinci/spark:latest /bin/sh</span><br></pre></td></tr></table></figure>
<p>运行官方示例：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/spark/bin/spark-submit --master spark://spark-master:7077 --class \</span><br><span class="line">    org.apache.spark.examples.SparkPi \</span><br><span class="line">    /spark/examples/jars/spark-examples_2.11-2.4.0.jar 1000</span><br></pre></td></tr></table></figure>
<p>输出：<code>Pi is roughly 3.1414315514143154</code></p>
<p>至此，本章教程结束。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/Livy-REST-API-封装（Java）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="姜文奇">
      <meta itemprop="description" content="大数据, 机器学习, 后端, 运维">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Vinci's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/Livy-REST-API-封装（Java）/" class="post-title-link" itemprop="url">Livy REST API 封装（Java）</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-03-10 00:01:46" itemprop="dateCreated datePublished" datetime="2019-03-10T00:01:46+08:00">2019-03-10</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-04-10 01:04:16" itemprop="dateModified" datetime="2019-04-10T01:04:16+08:00">2019-04-10</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>参考文章如下：</p>
<p><a href="https://blog.csdn.net/camel84/article/details/81990383" target="_blank" rel="noopener">https://blog.csdn.net/camel84/article/details/81990383</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1078857" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1078857</a></p>
<p>项目地址：<a href="https://github.com/JiangWenqi/LivyRESTAPI" target="_blank" rel="noopener">https://github.com/JiangWenqi/LivyRESTAPI</a></p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><blockquote>
<p>Livy is an open source REST interface for interacting with <a href="http://spark.apache.org/" target="_blank" rel="noopener">Apache Spark</a> from anywhere. It supports executing snippets of code or programs in a Spark context that runs locally or in <a href="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html" target="_blank" rel="noopener">Apache Hadoop YARN</a>.</p>
<ul>
<li>Interactive Scala, Python and R shells</li>
<li>Batch submissions in Scala, Java, Python</li>
<li>Multiple users can share the same server (impersonation support)</li>
<li>Can be used for submitting jobs from anywhere with REST</li>
<li>Does not require any code change to your programs</li>
</ul>
</blockquote>
<p>以上是<code>Livy</code>的官方介绍，具体使用请参照这篇<a href="https://blog.csdn.net/camel84/article/details/81990383" target="_blank" rel="noopener">文章</a>。</p>
<p>大体思路是用 <code>Java</code> 模拟发送请求报文给 <code>Livy</code>，</p>
<hr>
<h1 id="项目依赖"><a href="#项目依赖" class="headerlink" title="项目依赖"></a>项目依赖</h1><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.livy/livy-core --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.livy<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>livy-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.5.0-incubating<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.livy/livy-rsc --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.livy<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>livy-rsc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.5.0-incubating<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- https://mvnrepository.com/artifact/log4j/log4j --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.17<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>net.sf.json-lib<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>json-lib<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">classifier</span>&gt;</span>jdk15<span class="tag">&lt;/<span class="name">classifier</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.httpcomponents<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>httpclient<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.5.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.ibatis/ibatis-core --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.ibatis<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>ibatis-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.junit.jupiter<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit-jupiter-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>
<hr>
<h1 id="Spark-Job封装"><a href="#Spark-Job封装" class="headerlink" title="Spark Job封装"></a>Spark Job封装</h1><table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
<th>Type</th>
</tr>
</thead>
<tbody>
<tr>
<td>file</td>
<td>File containing the application to execute</td>
<td>path (required)</td>
</tr>
<tr>
<td>proxyUser</td>
<td>User to impersonate when running the job</td>
<td>string</td>
</tr>
<tr>
<td>className</td>
<td>Application Java/Spark main class</td>
<td>string</td>
</tr>
<tr>
<td>args</td>
<td>Command line arguments for the application</td>
<td>list of strings</td>
</tr>
<tr>
<td>jars</td>
<td>jars to be used in this session</td>
<td>list of strings</td>
</tr>
<tr>
<td>pyFiles</td>
<td>Python files to be used in this session</td>
<td>list of strings</td>
</tr>
<tr>
<td>files</td>
<td>files to be used in this session</td>
<td>list of strings</td>
</tr>
<tr>
<td>driverMemory</td>
<td>Amount of memory to use for the driver process</td>
<td>string</td>
</tr>
<tr>
<td>driverCores</td>
<td>Number of cores to use for the driver process</td>
<td>int</td>
</tr>
<tr>
<td>executorMemory</td>
<td>Amount of memory to use per executor process</td>
<td>string</td>
</tr>
<tr>
<td>executorCores</td>
<td>Number of cores to use for each executor</td>
<td>int</td>
</tr>
<tr>
<td>numExecutors</td>
<td>Number of executors to launch for this session</td>
<td>int</td>
</tr>
<tr>
<td>archives</td>
<td>Archives to be used in this session</td>
<td>List of string</td>
</tr>
<tr>
<td>queue</td>
<td>The name of the YARN queue to which submitted</td>
<td>string</td>
</tr>
<tr>
<td>name</td>
<td>The name of this session</td>
<td>string</td>
</tr>
<tr>
<td>conf</td>
<td>Spark configuration properties</td>
<td>Map of key=val</td>
</tr>
</tbody>
</table>
<p>这是原本是需要自己根据所需要的参数拼接 <code>json</code>，作为<code>request body</code>上传到Livy服务器，执行相应任务。</p>
<p>但是为了方便起见，我对该<code>request body</code>进行了封装。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> space.jwqwy.livy.entiy;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Livy REST API 封装</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Vinci</span></span><br><span class="line"><span class="comment"> * Create: 2019/02/18 16:37</span></span><br><span class="line"><span class="comment"> * Description: Request Body Livy 批处理任务 属性封装</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SparkJob</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 必须有</span></span><br><span class="line"><span class="comment">     * 包含需要执行应用的文件，主要是jar包</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> String file;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * User to impersonate when running the job</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> String proxyUser;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Application Java/Spark main class</span></span><br><span class="line"><span class="comment">     * 主类</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> String className;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Command line arguments for the application</span></span><br><span class="line"><span class="comment">     * 参数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> List&lt;String&gt; args;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * jars to be used in this session</span></span><br><span class="line"><span class="comment">     * 这个任务里面用到的其他 jar 包</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> List&lt;String&gt; jars;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Python files to be used in this session</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> List&lt;String&gt; pyFiles;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * files to be used in this session</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> List&lt;String&gt; files;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Amount of memory to use for the driver process</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> String driverMemory;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Number of cores to use for the driver process</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> driverCores;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Amount of memory to use per executor process</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> String executorMemory;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Number of cores to use for each executor</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> executorCores;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Number of executors to launch for this session</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> numExecutors;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Archives to be used in this session</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> List&lt;String&gt; archives;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * The name of the YARN queue to which submitted</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> String queue;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * The name of this session</span></span><br><span class="line"><span class="comment">     * 任务名称</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Spark configuration properties</span></span><br><span class="line"><span class="comment">     * spark 配置文件</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, Object&gt; conf;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getFile</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> file;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setFile</span><span class="params">(String file)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.file = file;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getProxyUser</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> proxyUser;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setProxyUser</span><span class="params">(String proxyUser)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.proxyUser = proxyUser;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getClassName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> className;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setClassName</span><span class="params">(String className)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.className = className;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;String&gt; <span class="title">getArgs</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> args;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setArgs</span><span class="params">(List&lt;String&gt; args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.args = args;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;String&gt; <span class="title">getJars</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> jars;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setJars</span><span class="params">(List&lt;String&gt; jars)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.jars = jars;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;String&gt; <span class="title">getPyFiles</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> pyFiles;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPyFiles</span><span class="params">(List&lt;String&gt; pyFiles)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.pyFiles = pyFiles;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;String&gt; <span class="title">getFiles</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> files;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setFiles</span><span class="params">(List&lt;String&gt; files)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.files = files;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getDriverMemory</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> driverMemory;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDriverMemory</span><span class="params">(String driverMemory)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.driverMemory = driverMemory;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getDriverCores</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> driverCores;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDriverCores</span><span class="params">(<span class="keyword">int</span> driverCores)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.driverCores = driverCores;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getExecutorMemory</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> executorMemory;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setExecutorMemory</span><span class="params">(String executorMemory)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.executorMemory = executorMemory;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getExecutorCores</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> executorCores;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setExecutorCores</span><span class="params">(<span class="keyword">int</span> executorCores)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.executorCores = executorCores;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getNumExecutors</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> numExecutors;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setNumExecutors</span><span class="params">(<span class="keyword">int</span> numExecutors)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.numExecutors = numExecutors;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;String&gt; <span class="title">getArchives</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> archives;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setArchives</span><span class="params">(List&lt;String&gt; archives)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.archives = archives;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getQueue</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> queue;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setQueue</span><span class="params">(String queue)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.queue = queue;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;String, Object&gt; <span class="title">getConf</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> conf;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setConf</span><span class="params">(Map&lt;String, Object&gt; conf)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.conf = conf;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="Http-Utils"><a href="#Http-Utils" class="headerlink" title="Http Utils"></a>Http Utils</h1><p><code>HttpUtils</code>是比较这个项目最为核心的工具类，用来模拟发送：<strong>POST,GET,DELETE</strong> 等报文请求。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> space.jwqwy.livy.util;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.http.HttpEntity;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.HttpResponse;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.client.methods.HttpDelete;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.client.methods.HttpGet;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.client.methods.HttpPost;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.entity.StringEntity;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.impl.client.CloseableHttpClient;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.impl.client.HttpClients;</span><br><span class="line"><span class="keyword">import</span> org.apache.http.util.EntityUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Livy REST API 封装</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Vinci</span></span><br><span class="line"><span class="comment"> * Create: 2019/02/19 15:35</span></span><br><span class="line"><span class="comment"> * Description: Http 报文</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HttpUtils</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * HttpGET请求</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> url     链接</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> headers 报文头</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 结果</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getAccess</span><span class="params">(String url, Map&lt;String, String&gt; headers)</span> </span>&#123;</span><br><span class="line">        String result = <span class="keyword">null</span>;</span><br><span class="line">        CloseableHttpClient httpClient = HttpClients.createDefault();</span><br><span class="line">        HttpGet httpGet = <span class="keyword">new</span> HttpGet(url);</span><br><span class="line">        <span class="keyword">if</span> (headers != <span class="keyword">null</span> &amp;&amp; headers.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            headers.forEach(httpGet::addHeader);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            HttpResponse response = httpClient.execute(httpGet);</span><br><span class="line">            HttpEntity entity = response.getEntity();</span><br><span class="line">            result = EntityUtils.toString(entity);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * HttpDelete请求</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> url     链接</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> headers 报文头</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 结果</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">deleteAccess</span><span class="params">(String url, Map&lt;String, String&gt; headers)</span> </span>&#123;</span><br><span class="line">        String result = <span class="keyword">null</span>;</span><br><span class="line">        CloseableHttpClient httpClient = HttpClients.createDefault();</span><br><span class="line">        HttpDelete httpDelete = <span class="keyword">new</span> HttpDelete(url);</span><br><span class="line">        <span class="keyword">if</span> (headers != <span class="keyword">null</span> &amp;&amp; headers.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            headers.forEach(httpDelete::addHeader);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            HttpResponse response = httpClient.execute(httpDelete);</span><br><span class="line">            HttpEntity entity = response.getEntity();</span><br><span class="line">            result = EntityUtils.toString(entity);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * HttpPost请求</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> url     url</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> headers 请求报文头</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> data    数据</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 结果</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">postAccess</span><span class="params">(String url, Map&lt;String, String&gt; headers, String data)</span> </span>&#123;</span><br><span class="line">        String result = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">        CloseableHttpClient httpClient = HttpClients.createDefault();</span><br><span class="line"></span><br><span class="line">        HttpPost post = <span class="keyword">new</span> HttpPost(url);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (headers != <span class="keyword">null</span> &amp;&amp; headers.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            headers.forEach(post::addHeader);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            StringEntity entity = <span class="keyword">new</span> StringEntity(data);</span><br><span class="line">            entity.setContentEncoding(<span class="string">"UTF-8"</span>);</span><br><span class="line">            entity.setContentType(<span class="string">"application/json"</span>);</span><br><span class="line">            post.setEntity(entity);</span><br><span class="line"></span><br><span class="line">            HttpResponse response = httpClient.execute(post);</span><br><span class="line">            HttpEntity resultEntity = response.getEntity();</span><br><span class="line">            result = EntityUtils.toString(resultEntity);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> result;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="Livy-Service及实现类"><a href="#Livy-Service及实现类" class="headerlink" title="Livy Service及实现类"></a>Livy Service及实现类</h1><h2 id="Livy-Service"><a href="#Livy-Service" class="headerlink" title="Livy Service"></a>Livy Service</h2><p>封装了一共有八个方法，具体作用看代码注释</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> space.jwqwy.livy.service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> space.jwqwy.livy.entiy.SparkJob;</span><br><span class="line"><span class="keyword">import</span> space.jwqwy.livy.eum.SparkJobState;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Livy REST API 封装</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Vinci</span></span><br><span class="line"><span class="comment"> * Create: 2019/02/19 15:01</span></span><br><span class="line"><span class="comment"> * Description: 如何通过Livy的RESTful API接口向CDH集群提交作业</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">LivyService</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 运行一个 SparkJob 一直等到他运行完成之后才会有返回值</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> job SparkJob</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 任务是否正确运行结束</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">runSparkJob</span><span class="params">(SparkJob job)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 后台启动一个 SparkJob</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> job SparkJob</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> SparkJob 的 batch session ID</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">runSparkJobBackground</span><span class="params">(SparkJob job)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 启动一个 session 运行 SparkJob, 不需要等待是否运行成功</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> job SparkJob</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> SparkJob 的 batch session ID</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">startSparkJob</span><span class="params">(SparkJob job)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询所有的 活跃的 Spark Job</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 所有活跃的 Spark Job = batch session</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">Map&lt;String, Object&gt; <span class="title">getActiveSparkJobs</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询具体的且活跃的 Spark Job 信息</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> sparkJobID SparkJob 的 ID（batch session ID）</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> Spark Job 信息 ，具体的 batch session 信息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">Map&lt;String, Object&gt; <span class="title">getSparkJobInfo</span><span class="params">(<span class="keyword">int</span> sparkJobID)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询具体的且活跃的 Spark Job 状态</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> sparkJobID SparkJob 的 ID（batch session ID）</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> Spark Job 状态 ，具体的 batch session 状态</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">SparkJobState <span class="title">getSparkJobState</span><span class="params">(<span class="keyword">int</span> sparkJobID)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询具体的且活跃的 Spark Job 日志</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> sparkJobID SparkJob 的 ID（batch session ID）</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> Spark Job 日志 ，具体的 batch session 日志</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">Map&lt;String, Object&gt; <span class="title">getSparkJoblog</span><span class="params">(<span class="keyword">int</span> sparkJobID)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Kills the Batch job.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> sparkJobID SparkJob 的 ID（batch session ID）</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> msg</span></span><br><span class="line"><span class="comment">     * &#123;</span></span><br><span class="line"><span class="comment">     * "msg": "deleted"</span></span><br><span class="line"><span class="comment">     * &#125;</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">Map&lt;String, Object&gt; <span class="title">deleteSparkJob</span><span class="params">(<span class="keyword">int</span> sparkJobID)</span></span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="Livy-Service实现类"><a href="#Livy-Service实现类" class="headerlink" title="Livy Service实现类"></a>Livy Service实现类</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> space.jwqwy.livy.service.impl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> net.sf.json.JSONObject;</span><br><span class="line"><span class="keyword">import</span> net.sf.json.JsonConfig;</span><br><span class="line"><span class="keyword">import</span> net.sf.json.util.PropertyFilter;</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger;</span><br><span class="line"><span class="keyword">import</span> space.jwqwy.livy.common.Constants;</span><br><span class="line"><span class="keyword">import</span> space.jwqwy.livy.entiy.SparkJob;</span><br><span class="line"><span class="keyword">import</span> space.jwqwy.livy.eum.SparkJobState;</span><br><span class="line"><span class="keyword">import</span> space.jwqwy.livy.service.LivyService;</span><br><span class="line"><span class="keyword">import</span> space.jwqwy.livy.util.HttpUtils;</span><br><span class="line"><span class="keyword">import</span> space.jwqwy.livy.util.PropertiesUtil;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Livy REST API 封装</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Vinci</span></span><br><span class="line"><span class="comment"> * Create: 2019/02/19 15:12</span></span><br><span class="line"><span class="comment"> * Description: Livy Service实现类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LivyServiceImpl</span> <span class="keyword">implements</span> <span class="title">LivyService</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Logger logger = Logger.getLogger(LivyServiceImpl.class);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> String LIVY_URL = <span class="string">""</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LivyServiceImpl</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Properties properties = PropertiesUtil.getProperties(<span class="string">"properties/livy.properties"</span>);</span><br><span class="line">            LIVY_URL = String.valueOf(properties.get(<span class="string">"LIVY_URL"</span>));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            logger.error(<span class="string">"请检查配置文件，找不到 Livy URL"</span>);</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">runSparkJob</span><span class="params">(SparkJob sparkJob)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sparkJobID = startSparkJob(sparkJob);</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            SparkJobState sparkJobState = getSparkJobState(sparkJobID);</span><br><span class="line">            <span class="keyword">switch</span> (sparkJobState) &#123;</span><br><span class="line">                <span class="keyword">case</span> SHUTTING_DOWN:</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                <span class="keyword">case</span> ERROR:</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                <span class="keyword">case</span> DEAD:</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                <span class="keyword">case</span> SUCCESS:</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">                <span class="keyword">default</span>:</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">// 休眠3s</span></span><br><span class="line">                Thread.sleep(<span class="number">3000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">                logger.error(ex.getMessage());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">runSparkJobBackground</span><span class="params">(SparkJob sparkJob)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> startSparkJob(sparkJob);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">startSparkJob</span><span class="params">(SparkJob sparkJob)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sparkJobID = -<span class="number">1</span>;</span><br><span class="line">        JSONObject batchSession = createBatch(parse2Json(sparkJob));</span><br><span class="line">        String state = batchSession.getString(Constants.LIVY_SESSION_STATE);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果 session 状态为 不为 dead 或者 error ，则返回 session id</span></span><br><span class="line">        SparkJobState sparkJobState = SparkJobState.fromDescription(state);</span><br><span class="line">        <span class="keyword">if</span> (sparkJobState != SparkJobState.DEAD &amp;&amp; sparkJobState != SparkJobState.ERROR) &#123;</span><br><span class="line">            sparkJobID = (<span class="keyword">int</span>) batchSession.get(Constants.LIVY_SESSION_ID);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            logger.error(<span class="string">"================ 创建Spark 任务失败=======================\n"</span>);</span><br><span class="line">            logger.error(<span class="string">"=====================失败原因:==========================\n"</span> + batchSession.toString());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> sparkJobID;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;String, Object&gt; <span class="title">getActiveSparkJobs</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> getBatchSessions();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;String, Object&gt; <span class="title">getSparkJobInfo</span><span class="params">(<span class="keyword">int</span> sparkJobID)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> getBatchSession(sparkJobID);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SparkJobState <span class="title">getSparkJobState</span><span class="params">(<span class="keyword">int</span> sparkJobID)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> getBatchSessionState(sparkJobID);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;String, Object&gt; <span class="title">getSparkJoblog</span><span class="params">(<span class="keyword">int</span> sparkJobID)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> getBatchSessionLog(sparkJobID);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;String, Object&gt; <span class="title">deleteSparkJob</span><span class="params">(<span class="keyword">int</span> sparkJobID)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> deleteBatchSession(sparkJobID);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 过滤器，把默认值的参数剔除掉</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> job Livy任务</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> jobJson</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> JSONObject <span class="title">parse2Json</span><span class="params">(SparkJob job)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 过滤器，把默认值的参数剔除掉</span></span><br><span class="line">        PropertyFilter filter = (source, name, value) -&gt; &#123;</span><br><span class="line">            <span class="comment">// 如果为数字则判断是否为0（默认值），如果为0，则为 true</span></span><br><span class="line">            <span class="keyword">if</span> (value <span class="keyword">instanceof</span> Number &amp;&amp; (<span class="keyword">int</span>) value == <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">null</span> == value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        JsonConfig jsonConfig = <span class="keyword">new</span> JsonConfig();</span><br><span class="line">        jsonConfig.setJsonPropertyFilter(filter);</span><br><span class="line">        <span class="keyword">return</span> JSONObject.fromObject(job, jsonConfig);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建一个 Batch Session 执行 SparkJob</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> sparkJobJson sparkJob json 形式</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 该 job 的 batch session 信息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> JSONObject <span class="title">createBatch</span><span class="params">(JSONObject sparkJobJson)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 将 Map 转为字符串</span></span><br><span class="line">        String sparkJobJsonStr = JSONObject.fromObject(sparkJobJson).toString();</span><br><span class="line">        <span class="keyword">return</span> createBatch(sparkJobJsonStr);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建一个 Batch Session 执行 SparkJob</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> sparkJobJsonStr sparkJob 字符串形式</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 该 job 的 batch session 信息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> JSONObject <span class="title">createBatch</span><span class="params">(String sparkJobJsonStr)</span> </span>&#123;</span><br><span class="line">        JSONObject resultJson = <span class="keyword">null</span>;</span><br><span class="line">        Map&lt;String, String&gt; headers = <span class="keyword">new</span> HashMap&lt;&gt;(<span class="number">4</span>);</span><br><span class="line">        headers.put(<span class="string">"Accept"</span>, <span class="string">"application/json"</span>);</span><br><span class="line">        headers.put(<span class="string">"Content-Type"</span>, <span class="string">"application/json"</span>);</span><br><span class="line">        headers.put(<span class="string">"Accept-Charset"</span>, <span class="string">"utf-8"</span>);</span><br><span class="line"></span><br><span class="line">        String result = HttpUtils.postAccess(LIVY_URL + <span class="string">"/batches"</span>, headers, sparkJobJsonStr);</span><br><span class="line">        <span class="keyword">if</span> (result != <span class="keyword">null</span>) &#123;</span><br><span class="line">            resultJson = JSONObject.fromObject(result);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            logger.error(<span class="string">"\n==============Livy 提交批任务失败==================\n"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> resultJson;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Map&lt;String, Object&gt; <span class="title">getBatchSessions</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        JSONObject resultJson = <span class="keyword">null</span>;</span><br><span class="line">        String result = HttpUtils.getAccess(LIVY_URL + <span class="string">"/batches"</span>, <span class="keyword">null</span>);</span><br><span class="line">        <span class="keyword">if</span> (result != <span class="keyword">null</span>) &#123;</span><br><span class="line">            resultJson = JSONObject.fromObject(result);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            logger.error(<span class="string">"\n==============Livy 查询批任务失败==================\n"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> resultJson;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Map&lt;String, Object&gt; <span class="title">getBatchSession</span><span class="params">(<span class="keyword">int</span> batchID)</span> </span>&#123;</span><br><span class="line">        JSONObject resultJson = <span class="keyword">null</span>;</span><br><span class="line">        String result = HttpUtils.getAccess(LIVY_URL + <span class="string">"/batches/"</span> + batchID, <span class="keyword">null</span>);</span><br><span class="line">        <span class="keyword">if</span> (result != <span class="keyword">null</span>) &#123;</span><br><span class="line">            resultJson = JSONObject.fromObject(result);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            logger.error(<span class="string">"\n==============Livy 查询具体任务失败，任务编号为：\n"</span> + batchID + <span class="string">"\n"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> resultJson;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> SparkJobState <span class="title">getBatchSessionState</span><span class="params">(<span class="keyword">int</span> batchID)</span> </span>&#123;</span><br><span class="line">        SparkJobState sparkJobState = <span class="keyword">null</span>;</span><br><span class="line">        String result = HttpUtils.getAccess(LIVY_URL + <span class="string">"/batches/"</span> + batchID + <span class="string">"/state"</span>, <span class="keyword">null</span>);</span><br><span class="line">        <span class="keyword">if</span> (result != <span class="keyword">null</span>) &#123;</span><br><span class="line">            JSONObject resultJson = JSONObject.fromObject(result);</span><br><span class="line">            String state = resultJson.getString(<span class="string">"state"</span>);</span><br><span class="line">            sparkJobState = SparkJobState.fromDescription(state);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            logger.error(<span class="string">"\n==============Livy 查询具体任务状态失败，任务编号为：\n"</span> + batchID);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> sparkJobState;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Map&lt;String, Object&gt; <span class="title">getBatchSessionLog</span><span class="params">(<span class="keyword">int</span> batchID)</span> </span>&#123;</span><br><span class="line">        JSONObject resultJson = <span class="keyword">null</span>;</span><br><span class="line">        String result = HttpUtils.getAccess(LIVY_URL + <span class="string">"/batches/"</span> + batchID + <span class="string">"/log"</span>, <span class="keyword">null</span>);</span><br><span class="line">        <span class="keyword">if</span> (result != <span class="keyword">null</span>) &#123;</span><br><span class="line">            resultJson = JSONObject.fromObject(result);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            logger.error(<span class="string">"\n==============Livy 查询具体任务日志失败，任务编号为：\n"</span> + batchID + <span class="string">"\n"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> resultJson;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Map&lt;String, Object&gt; <span class="title">deleteBatchSession</span><span class="params">(<span class="keyword">int</span> batchID)</span> </span>&#123;</span><br><span class="line">        JSONObject resultJson = <span class="keyword">null</span>;</span><br><span class="line">        String result = HttpUtils.deleteAccess(LIVY_URL + <span class="string">"/batches/"</span> + batchID, <span class="keyword">null</span>);</span><br><span class="line">        <span class="keyword">if</span> (result != <span class="keyword">null</span>) &#123;</span><br><span class="line">            resultJson = JSONObject.fromObject(result);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            logger.error(<span class="string">"\n==============Livy 删除具体任务失败，任务编号为：\n"</span> + batchID + <span class="string">"\n"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> resultJson;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="Livy-Service-测试"><a href="#Livy-Service-测试" class="headerlink" title="Livy Service 测试"></a>Livy Service 测试</h1><h2 id="第一步：上传-jar-包"><a href="#第一步：上传-jar-包" class="headerlink" title="第一步：上传 jar 包"></a>第一步：上传 jar 包</h2><p>上传测试所用的<code>jar</code>包到<code>hdfs</code>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_USER_NAME=hdfs</span><br><span class="line"><span class="variable">$&#123;HADOOP_HOME&#125;</span>/bin/hdfs dfs -mkdir /testJars</span><br><span class="line"><span class="variable">$&#123;HADOOP_HOME&#125;</span>/bin/hdfs dfs -put /opt/cloudera/parcels/SPARK2-2.3.0.cloudera4-1.cdh5.13.3.p0.611179/lib/spark2/examples/jars/spark-examples_2.11-2.3.0.cloudera4.jar /testJars/</span><br></pre></td></tr></table></figure>
<h2 id="第二步：创建-Spark-Job"><a href="#第二步：创建-Spark-Job" class="headerlink" title="第二步：创建 Spark Job"></a>第二步：创建 Spark Job</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">SparkJob job = <span class="keyword">new</span> SparkJob();</span><br><span class="line"></span><br><span class="line">job.setFile(<span class="string">"hdfs://192.168.1.170:8020/testJars/spark-examples_2.11-2.3.0.cloudera4.jar"</span>);</span><br><span class="line">job.setClassName(<span class="string">"org.apache.spark.examples.SparkPi"</span>);</span><br><span class="line">job.setName(<span class="string">"SparkPi"</span>);</span><br><span class="line">job.setExecutorCores(<span class="number">3</span>);</span><br></pre></td></tr></table></figure>
<h2 id="第三部：执行任务，查询任务状态等操作"><a href="#第三部：执行任务，查询任务状态等操作" class="headerlink" title="第三部：执行任务，查询任务状态等操作"></a>第三部：执行任务，查询任务状态等操作</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> sparkJobID = livyService.startSparkJob(job);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (sparkJobID &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    System.out.println(<span class="string">"\n创建任务，任务ID为：\n"</span> + sparkJobID);</span><br><span class="line"></span><br><span class="line">    Map&lt;String, Object&gt; activeSparkJobs = livyService.getActiveSparkJobs();</span><br><span class="line">    System.out.println(<span class="string">"\n查询当前所有任务：\n"</span> + activeSparkJobs.toString());</span><br><span class="line"></span><br><span class="line">    Map&lt;String, Object&gt; info = livyService.getSparkJobInfo(sparkJobID);</span><br><span class="line">    System.out.println(<span class="string">"\n查询任务ID为"</span> + sparkJobID + <span class="string">"的任务详情:\n"</span> + info.toString());</span><br><span class="line"></span><br><span class="line">    SparkJobState state = livyService.getSparkJobState(sparkJobID);</span><br><span class="line">    System.out.println(<span class="string">"\n查询任务ID为"</span> + sparkJobID + <span class="string">"的任务状态:\n"</span> + state);</span><br><span class="line"></span><br><span class="line">    Map&lt;String, Object&gt; log = livyService.getSparkJoblog(sparkJobID);</span><br><span class="line">    System.out.println(<span class="string">"\n查询任务ID为"</span> + sparkJobID + <span class="string">"的任务日志:\n"</span> + log.toString());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Map&lt;String, Object&gt; del = livyService.deleteSparkJob(sparkJobID);</span></span><br><span class="line">    <span class="comment">// System.out.println("删除任务ID为" + sparkJobID + "\n" + del.toString());</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 执行任务，一直到任务结束</span></span><br><span class="line"><span class="comment">// System.out.println(runSparkJob(job));</span></span><br></pre></td></tr></table></figure>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/集群配置Livy/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="姜文奇">
      <meta itemprop="description" content="大数据, 机器学习, 后端, 运维">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Vinci's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/集群配置Livy/" class="post-title-link" itemprop="url">集群配置Livy</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-27 23:06:33" itemprop="dateCreated datePublished" datetime="2019-02-27T23:06:33+08:00">2019-02-27</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-04-10 01:09:46" itemprop="dateModified" datetime="2019-04-10T01:09:46+08:00">2019-04-10</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="集群配置Livy"><a href="#集群配置Livy" class="headerlink" title="集群配置Livy"></a>集群配置Livy</h1><h2 id="一、下载"><a href="#一、下载" class="headerlink" title="一、下载"></a>一、下载</h2><p>Livy 官网地址：<code>http://livy.incubator.apache.org/download/</code></p>
<p>具体指令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 进入指定目录</span><br><span class="line">cd /home/admin/soft</span><br><span class="line"><span class="meta">#</span> 下载文件</span><br><span class="line">wget http://mirror.bit.edu.cn/apache/incubator/livy/0.5.0-incubating/livy-0.5.0-incubating-bin.zip</span><br></pre></td></tr></table></figure>
<h2 id="二、解压"><a href="#二、解压" class="headerlink" title="二、解压"></a>二、解压</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">unzip livy-0.5.0-incubating-bin.zip</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重命名</span></span><br><span class="line">mv livy-0.5.0-incubating-bin livy-0.5.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 复制到 /etc 目录下</span></span><br><span class="line">cp -r livy-0.5.0 /etc/livy</span><br></pre></td></tr></table></figure>
<h2 id="三、更改配置文件"><a href="#三、更改配置文件" class="headerlink" title="三、更改配置文件"></a>三、更改配置文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd /etc</span><br><span class="line"><span class="meta">#</span><span class="bash"> 给文件夹赋予权限</span></span><br><span class="line">chmod +777 livy</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置文件</span></span><br><span class="line">cd /etc/livy/conf</span><br><span class="line">cp livy-env.sh.template livy-env.sh</span><br><span class="line">vim livy-env.sh</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># - HADOOP_CONF_DIR Directory containing the Hadoop / YARN configuration to use.</span><br><span class="line">HADOOP_CONF_DIR=/etc/hadoop/conf</span><br><span class="line"># - SPARK_HOME      Spark which you would like to use in Livy.</span><br><span class="line">SPARK_HOME=/opt/cloudera/parcels/SPARK2-2.3.0.cloudera4-1.cdh5.13.3.p0.611179/lib/spark2</span><br></pre></td></tr></table></figure>
<h2 id="四、启动服务"><a href="#四、启动服务" class="headerlink" title="四、启动服务"></a>四、启动服务</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/livy</span><br><span class="line"><span class="meta">#</span><span class="bash"> 新建日志目录，并给权限</span></span><br><span class="line">mkdir logs</span><br><span class="line">chmod +777 logs</span><br><span class="line">./bin/livy-server</span><br></pre></td></tr></table></figure>
<p>启动成功：</p>
<img src="/2019/02/集群配置Livy/启动成功.png" title="启动成功">
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">后台模式</span></span><br><span class="line">./bin/livy-server start</span><br></pre></td></tr></table></figure>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">姜文奇</p>
              <div class="site-description motion-element" itemprop="description">大数据, 机器学习, 后端, 运维</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">4</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">2</span>
                    <span class="site-state-item-name">categories</span>
                  
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">7</span>
                    <span class="site-state-item-name">tags</span>
                  
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">姜文奇</span>

  

  
</div>


  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.1.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.1.0"></script>

  <script src="/js/motion.js?v=7.1.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.1.0"></script>



  

  


  <script src="/js/next-boot.js?v=7.1.0"></script>


  

  

  

  



  




  

  

  

  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
